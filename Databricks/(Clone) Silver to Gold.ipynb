{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e6ccfd5-bc7c-45fb-b306-dbbb38dcd307",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**SINGLE TABLE COLUMN TRANSFORMATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb6abdb8-b44b-4483-bb43-3331c0d9e1e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls('mnt/silver/SalesLT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7de9d84c-ab81-42cc-8ec8-a192d85f0f72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls('mnt/gold/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31665fe4-72f3-4d63-b363-bd11ce953f42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('delta').load('/mnt/silver/SalesLT/Address/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7ba79a8-6624-4c95-a673-5066a4d7b9cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2166ae32-7c13-407f-865e-117622a36998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Convert column names from PascalCase or camelCase to snake_case in a PySpark DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame with columns to be renamed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with column names converted to snake_case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "475cc0e4-ca78-48a6-9657-7720f1cecb40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "def rename_columns_to_snake_case(df):\n",
    "    #Get the list of column names\n",
    "    column_names = df.columns\n",
    "\n",
    "    #dictionary to hold old and new column names mappings\n",
    "    rename_map = {}\n",
    "\n",
    "    for old_col_name in column_names:\n",
    "      #convert column names from PascalCase or camelCase to snake_case\n",
    "      new_col_name = \"\".join([\n",
    "        \"_\" + char.lower() if (\n",
    "          char.isupper()\n",
    "          and idx > 0\n",
    "          and not old_col_name[idx - 1].isupper()\n",
    "        ) else char.lower()\n",
    "        for idx, char in enumerate(old_col_name)\n",
    "      ]).lstrip(\"_\")\n",
    "\n",
    "      #avoid renaming to an existing column name\n",
    "      if new_col_name in rename_map.values():\n",
    "        raise ValueError(f\"Duplicate column name found after renaming: '{new_col_name}'\")\n",
    "\n",
    "      #map the old column name to the new column name\n",
    "      rename_map[old_col_name] = new_col_name\n",
    "\n",
    "    #rename columns using the mapping\n",
    "    for old_col_name, new_col_name in rename_map.items():\n",
    "      df = df.withColumnRenamed(old_col_name, new_col_name)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "375e7560-5987-4db3-b27e-c5303fd78226",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = rename_columns_to_snake_case(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ef05330-04b3-46df-a4e0-6911e6a2244b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "024cf5d4-741f-4a7b-9de1-226d30878d52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**All table columns transformation (col names)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "add02a37-5680-48c9-8729-4a3932e6123d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = []\n",
    "\n",
    "for i in dbutils.fs.ls('mnt/silver/SalesLT'):   table_name.append(i.name.split('/')[0])\n",
    "\n",
    "table_name   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "015e33d2-97c5-48b1-be1d-a53b161aff42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for name in table_name:\n",
    "    path = '/mnt/silver/SalesLT/' + name\n",
    "    print(path)\n",
    "    df = spark.read.format('delta').load(path)\n",
    "\n",
    "    df = rename_columns_to_snake_case(df)\n",
    "\n",
    "    output_path = '/mnt/gold/SalesLT' + name + '/'\n",
    "    df.write.format('delta').mode('overwrite').save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d0b551b-f67b-436b-8670-d8d28f58f8a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81228a77-8fcd-478f-b78c-1be3167f518e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for name in table_name:\n",
    "    path = '/mnt/silver/SalesLT/' + name\n",
    "    print(path)\n",
    "    df = spark.read.format('delta').load(path)\n",
    "\n",
    "    df = rename_columns_to_snake_case(df)\n",
    "\n",
    "    output_path = '/mnt/gold/SalesLT/' + name + '/'\n",
    "    df.write.format('delta').mode('overwrite').save(output_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) Silver to Gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
